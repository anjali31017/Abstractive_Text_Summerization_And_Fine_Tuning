{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6549a868-b8ec-4734-be18-afdd479759de",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7340e611-1151-4693-b74f-ac4640004782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from rouge_score import rouge_scorer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc08c67-afc7-4f8a-81ab-93563f506b1d",
   "metadata": {},
   "source": [
    "# 2. Load Dataset (small subset for CPU-friendly training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25d896c-8f40-415a-89fd-8b1c434ad154",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "train_dataset = dataset['train'].select(range(2000))\n",
    "val_dataset = dataset['validation'].select(range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1914a-21f3-4123-8f54-39959f3697df",
   "metadata": {},
   "source": [
    "# 3. Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea7f98d-2941-4c3d-8756-651140f2eec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e2c112b8354a8daf2b4dc16ecadbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fd1ae8358e4b85ac0185e0e0353514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x: {\n",
    "        \"article\": preprocess_text(x[\"article\"]),\n",
    "        \"summary\": preprocess_text(x[\"highlights\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda x: {\n",
    "        \"article\": preprocess_text(x[\"article\"]),\n",
    "        \"summary\": preprocess_text(x[\"highlights\"])\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c5589-af9a-405f-9c6a-6e1c21e71138",
   "metadata": {},
   "source": [
    "# 4. Load DistilBART (lighter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe244b7-b582-4fdb-813f-f12a2999912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85df8b55211c4ea5b75dd2cf75ea4529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1045d5c015f44c0dbeecd45879813806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683b758075914774a2ab0d29ddcecf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c241af85936b4791b7778b8e841a8334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd978836a6c4957a53fa018de3b179d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b35b06-4da4-4c26-b3d0-97be6b2a9055",
   "metadata": {},
   "source": [
    "# 5. Apply LoRA (makes training possible on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd3d7dfe-0e86-4f6e-9e7f-717896fe786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 786,432 || all params: 306,296,832 || trainable%: 0.2568\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42831a-6134-4af4-8547-c422cc121a5f",
   "metadata": {},
   "source": [
    "# 6. Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbe1f37-273e-4030-9bc8-5b9ec1d7b86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3ab067537d4f8ab247262b0e3260d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjali/Documents/projects/Abstractive_Text_Summerization_And_Fine_Tuning/env/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6901ee6cc44a4dac92a1c6e8949df066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"article\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch[\"summary\"],\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bd513-4edb-4726-81a1-8fe42d2948d0",
   "metadata": {},
   "source": [
    "# 7. Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabb0cf3-609d-4137-867b-f7d2d0c19484",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bart_lora\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,   # effective batch size = 8\n",
    "    optim=\"adafactor\",\n",
    "    learning_rate=5e-4,\n",
    "    logging_steps=50,\n",
    "    save_steps=300,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef222d91-756b-4395-ad13-0310a52afb04",
   "metadata": {},
   "source": [
    "# 8. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f11718b-2117-4e84-9a25-d1b756cdc3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjali/Documents/projects/Abstractive_Text_Summerization_And_Fine_Tuning/env/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 2:12:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.868500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.652800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.494100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.485600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.477800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.441200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=1.8600693817138672, metrics={'train_runtime': 7983.9807, 'train_samples_per_second': 0.501, 'train_steps_per_second': 0.063, 'total_flos': 3105487847424000.0, 'train_loss': 1.8600693817138672, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeccd8e-36f7-4380-b3c7-8c29dc9447aa",
   "metadata": {},
   "source": [
    "# 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c833712d-f2bf-465e-896a-f09358a16ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../bart_lora/tokenizer_config.json',\n",
       " '../bart_lora/special_tokens_map.json',\n",
       " '../bart_lora/vocab.json',\n",
       " '../bart_lora/merges.txt',\n",
       " '../bart_lora/added_tokens.json',\n",
       " '../bart_lora/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../bart_lora\")\n",
    "tokenizer.save_pretrained(\"../bart_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f7510-048e-49c6-817c-e02198ff04eb",
   "metadata": {},
   "source": [
    "# 10. Example Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d3c14a3-3705-4ce1-9ceb-f7e0fba87d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Summary:\n",
      " The two men killed as they floated holding onto their capsized boat in a secondary strike in early September did not appear to have radio or other communications devices, the top military official overseeing the strike told lawmakers on Thursday . Adm. Frank \"Mitch\" Bradley was in charge of Joint Special Operations Command at the time of the strike .\n"
     ]
    }
   ],
   "source": [
    "example_text = \" The two men killed as they floated holding onto their capsized boat in a secondary strike against a suspected drug vessel in early September did not appear to have radio or other communications devices, the top military official overseeing the strike told lawmakers on Thursday, according to three sources with direct knowledge of his congressional briefings.As far back as September, defense officials have been quietly pushing back on criticism that killing the two survivors amounted to a war crime by arguing, in part, that they were legitimate targets because they appeared to be radioing for help or backup — reinforcements that, if they had received it, could have theoretically allowed them to continue to traffic the drugs aboard their sinking ship. Defense officials made that claim in at least one briefing in September for congressional staff, according to a source familiar with the session, and several media outlets cited officials repeating that justification in the last week. But Thursday, Adm. Frank “Mitch” Bradley acknowledged that the two survivors of the military’s initial strike were in no position to make a distress call in his briefings to lawmakers. Bradley was in charge of Joint Special Operations Command at the time of the strike and was the top military officer directing the attack. The initial hit on the vessel, believed to be carrying cocaine, killed nine people immediately and split the boat in half, capsizing it and sending a massive smoke plume into the sky, the sources who viewed the video as part of the briefings said. Part of the surveillance video was a zoomed-in, higher-definition view of the two survivors clinging to a still-floating, capsized portion, they said. For a little under an hour — 41 minutes, according to a separate US official — Bradley and the rest of the US military command center discussed what to do as they watched the men struggle to overturn what was left of their boat, the sources said. \"\n",
    "\n",
    "encoded = tokenizer(example_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "summary_ids = model.generate(encoded[\"input_ids\"], num_beams=4, max_length=128)\n",
    "print(\"\\nGenerated Summary:\")\n",
    "result = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c5bd939-a037-4ce4-a6de-6b0c6395d774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters:  1965\n",
      "Summerized characters:  353\n"
     ]
    }
   ],
   "source": [
    "print(\"Total characters: \",len(example_text))\n",
    "print(\"Summerized characters: \",len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf624cd0-91e1-46be-a18e-8127ebff3f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
